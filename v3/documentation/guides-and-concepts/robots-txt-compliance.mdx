---
title: Robots.txt compliance in News API v3
sidebarTitle: Robots.txt compliance
description:
  Understand robots.txt compliance fields and parameters in News API v3 to build
  applications that respect publisher permissions
---

News API v3 includes robots.txt compliance information with every article,
helping you build applications that respect publisher permissions. This feature
provides transparency about whether content adheres to the source website's
automated access guidelines.

## What is robots.txt compliance?

Robots.txt files allow website publishers to specify which parts of their site
can be accessed by automated tools. News API v3 respects these guidelines by
marking each article with its compliance status.

<Note>
  The robots.txt compliance check is performed at the time of article collection
  and reflects the publisher's guidelines at that moment.
</Note>

## The robots_compliant field

Each API response includes a `robots_compliant` boolean field indicating if
content can be safely accessed according to the publisher's guidelines. If true,
automated access is allowed; if false, it is restricted.

```json {6}
{
  "title": "Revolutionary AI Technology Breakthrough",
  "author": "Jane Smith",
  "domain_url": "techcrunch.com",
  "content": "Scientists have made a groundbreaking discovery...",
  "robots_compliant": true
  // other article field
}
```

## Filtering by compliance

Use the optional `robots_compliant` parameter to filter your API requests. This
parameter works with all endpoints that return articles.

<Tabs>
  <Tab title="All articles">
    ```json
    {
      "q": "artificial intelligence"
    }
    ```
    If the parameter is ommited, the API returns all articles with compliance status indicated (default behavior).
  </Tab>
  <Tab title="Compliant only">
    ```json
    {
      "q": "artificial intelligence",
      "robots_compliant": true
    }
    ```
    Returns only articles that comply with publisher guidelines.
  </Tab>
  <Tab title="Non-compliant only">
    ```json
    {
      "q": "artificial intelligence",
      "robots_compliant": false
    }
    ```
    Returns only articles flagged as non-compliant.
  </Tab>
</Tabs>

## Benefits

<CardGroup cols={2}>
  <Card title="Legal compliance" icon="shield-check">
    Reduce legal risks by respecting publisher-defined access policies and
    maintaining good relationships with content providers.
  </Card>
  <Card title="Performance optimization" icon="gauge">
    Filter non-compliant content server-side, reducing unnecessary data transfer
    and improving application performance.
  </Card>
  <Card title="Publisher relations" icon="handshake">
    Demonstrate respect for content providers' access policies, fostering better
    long-term partnerships.
  </Card>
  <Card title="Transparency" icon="eye">
    Clear visibility into which content can be safely used, enabling informed
    decisions about content usage.
  </Card>
</CardGroup>

## Implementation considerations

<AccordionGroup>
  <Accordion title="Always present in responses">
    The `robots_compliant` field is included in every article object, ensuring
    consistent access to compliance information regardless of filtering.
  </Accordion>
  <Accordion title="Optional parameter">
    You can include the `robots_compliant` parameter in requests to filter
    results, or omit it to receive all content with compliance flags.
  </Accordion>
  <Accordion title="Server-side filtering">
    When you use the parameter, filtering happens at the API level, improving
    performance by reducing unnecessary data transfer.
  </Accordion>
  <Accordion title="Boolean values only">
    The parameter accepts `true` to show only compliant content, `false` for
    non-compliant content, or can be omitted entirely.
  </Accordion>
</AccordionGroup>

## See also

- [API Reference](/v3/api-reference/endpoints/search/search-articles-get)
- [Error handling](/v3/documentation/troubleshooting/error-handling)
